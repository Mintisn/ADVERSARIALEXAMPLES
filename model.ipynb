{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26286cd0a70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "cuda = torch.device('cuda')\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('../data_row/', train=True, download=False,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor()\n",
    "                               ])),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('../data_row/', train=False, download=False,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor()\n",
    "                               ])),\n",
    "    batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net().cuda()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data=data.cuda()\n",
    "        target=target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), './model.pth')\n",
    "            torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data=data.cuda()\n",
    "            target=target.cuda()\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32571\\AppData\\Local\\Temp\\ipykernel_8548\\4224729980.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300651\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.321117\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.319974\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.299370\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.291290\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.312634\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.301124\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.314018\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.299428\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.304534\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.291025\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.293091\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.283573\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.285419\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.290574\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.302167\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.274162\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.290471\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.279954\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.287191\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.274851\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.275485\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.265381\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.266367\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.243978\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.285740\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.273854\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.262319\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.242277\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.248791\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.241235\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.214902\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.243472\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.247289\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.233138\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.213655\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.240785\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.208299\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.176254\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.175739\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.195697\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.161474\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.147990\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.176902\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.049459\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.092809\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.031651\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.095558\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.972982\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.980345\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.979960\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.916181\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.948350\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.805881\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.679365\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.730918\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.737574\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.733899\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.691153\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.789140\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.730391\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.460838\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.720108\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.569554\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.300039\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.686715\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.324036\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.360492\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.506697\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.325780\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.291769\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 1.337283\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.240751\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.493802\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.218555\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.198341\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.330276\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.194616\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.366058\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.105827\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.822774\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.246880\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.797555\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.319015\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.060235\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.073343\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.171513\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.147449\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.074189\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.861705\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.234858\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.968255\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.028997\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.109156\n",
      "\n",
      "Test set: Avg. loss: 0.6437, Accuracy: 8200/10000 (82%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.881659\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.882364\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.739191\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.995073\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.003712\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.874554\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.980227\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.933063\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.940722\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.897814\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.903983\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.979359\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.837292\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 1.005673\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.793321\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.877653\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.736365\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.775623\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.954811\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.795538\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.842609\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.771879\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.899507\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.045504\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.615983\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.908120\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.830148\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.920430\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.833083\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.868613\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.569347\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.805924\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.704428\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.650689\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.872383\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.856423\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.592483\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.767181\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.546772\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.778179\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.644905\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.955575\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.621367\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.536561\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.548474\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.576443\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.811328\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.770644\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.689319\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.692382\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.574516\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.723835\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.694245\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.674370\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.878459\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.656662\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.648381\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.726005\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.663271\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.560264\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.625162\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.678006\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.855695\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.518443\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.859486\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.732036\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.666943\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.576589\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.633290\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.485236\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.629270\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.610379\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.428783\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.483399\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.603601\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.567286\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.713385\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.472988\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.641813\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.590443\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.502192\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.537253\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.500625\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.625772\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.812709\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.503015\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.496702\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.682318\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.679500\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.363074\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.379448\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.378702\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.532476\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.687071\n",
      "\n",
      "Test set: Avg. loss: 0.3281, Accuracy: 9069/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.405459\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.374154\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.457879\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.522713\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.666109\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.489467\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.777273\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.436584\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.722876\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.509829\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.523320\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.516044\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.413640\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.501235\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.631037\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.530169\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.470447\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.486049\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.420978\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.584857\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.647761\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.322428\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.548746\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.568400\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.539877\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.645183\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.857347\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.569058\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.465595\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.547003\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.389771\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.409869\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.514528\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.428966\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.520600\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.673861\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.575734\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.454760\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.444079\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.599213\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.361041\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.552068\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.533530\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.699955\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.598018\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.539009\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.621019\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.703877\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.377840\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.529415\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.569576\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.482724\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.651556\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.338386\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.475954\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.552063\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.803674\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.517928\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.550227\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.504561\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.545464\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.666975\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.506264\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.503263\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.521280\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.370305\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.240090\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.346446\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.407403\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.464626\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.570900\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.875549\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.510659\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.455001\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.454513\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.532772\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.587753\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.620873\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.381713\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.500302\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.464964\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.532571\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.568667\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.388877\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.603433\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.432410\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.536695\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.689156\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.689678\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.579857\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.477740\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.606627\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.296081\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.517371\n",
      "\n",
      "Test set: Avg. loss: 0.2347, Accuracy: 9317/10000 (93%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.471750\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.327305\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.448595\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.560793\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.432581\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.298624\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.557062\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.750519\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.320333\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.312014\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.380112\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.401213\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.531298\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.462934\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.451857\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.472068\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.253473\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.674434\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.427944\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.231645\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.418854\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.501157\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.457788\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.247650\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.329323\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.530098\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.372369\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.352159\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.349628\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.505412\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.388350\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.568334\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.380728\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.371222\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.437299\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.505589\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.322134\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.434131\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.345347\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.694134\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.277465\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.510224\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.349987\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.391008\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.347637\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.290645\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.583669\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.547148\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.477559\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.450566\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.426691\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.359852\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.253778\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.417473\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.414248\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.211071\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.479903\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.528676\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.549548\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.268989\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.363836\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.553009\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.392191\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.517938\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.416712\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.470694\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.452146\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.462820\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.317800\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.602572\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.271354\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.489943\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.560173\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.461062\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.298891\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.480676\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.323217\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.450375\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.343557\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.436188\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.425209\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.410950\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.457601\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.564368\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.681813\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.452733\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.567062\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.334225\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.486606\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.428728\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.270845\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.330931\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.361928\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.194977\n",
      "\n",
      "Test set: Avg. loss: 0.1880, Accuracy: 9414/10000 (94%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.584641\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.711196\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.325942\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.268477\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.324928\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.400727\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.260140\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.278604\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.609266\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.365071\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.556324\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.249143\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.312456\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.416279\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.217260\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.519523\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.318694\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.405483\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.388520\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.371732\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.493246\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.389907\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.302196\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.358978\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.388512\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.308620\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.580007\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.391894\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.281681\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.363773\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.297590\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.793005\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.412120\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.498585\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.218425\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.489440\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.285336\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.292679\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.332614\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.484888\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.544846\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.298049\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.420217\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.268125\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.555826\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.284366\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.292131\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.309672\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.327330\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.448821\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.405259\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.574941\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.262548\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.279177\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.508679\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.558097\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.404429\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.241890\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.285600\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.543420\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.319771\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.337808\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.687669\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.360913\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.472489\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.381374\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.365483\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.226981\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.402931\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.413692\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.329587\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.202699\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.324944\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.597922\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.366384\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.407022\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.381161\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.386215\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.445859\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.243822\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.364329\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.339980\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.177519\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.473061\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.534167\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.334788\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.407999\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.304927\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.347291\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.647312\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.232519\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.362451\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.335127\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.293628\n",
      "\n",
      "Test set: Avg. loss: 0.1559, Accuracy: 9536/10000 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.479410\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.278105\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.286962\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.305871\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.509894\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.261634\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.330218\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.203302\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.233116\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.434461\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.462693\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.237252\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.169440\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.387312\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.595672\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.402137\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.326808\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.238927\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.262304\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.200630\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.415646\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.227230\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.380596\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.585585\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.465569\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.359064\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.336125\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.264133\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.286717\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.285260\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.437507\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.394139\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.361578\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.258866\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.293941\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.322679\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.219158\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.261027\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.252044\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.244123\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.215590\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.242528\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.368487\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.373327\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.309421\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.281505\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.729616\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.508781\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.306976\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.714410\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.561958\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.424649\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.641401\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.283954\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.434483\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.268951\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.272523\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.389717\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.343173\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.365072\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.306328\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.501930\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.301344\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.250869\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.290723\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.269597\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.106055\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.333428\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.294501\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.446641\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.255056\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.326385\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.431849\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.259582\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.465945\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.356245\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.221829\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.248418\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.224720\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.266143\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.226089\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.329313\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.237494\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.290349\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.237088\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.307087\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.340377\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.153355\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.274676\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.332926\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.443436\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.398498\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.555715\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.251629\n",
      "\n",
      "Test set: Avg. loss: 0.1341, Accuracy: 9586/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.357377\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.326591\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.245650\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.283248\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.326054\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.376026\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.215889\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.287371\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.418382\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.244299\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.221731\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.165839\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.513942\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.214642\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.137268\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.225443\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.167510\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.219458\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.191029\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.418830\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.257097\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.228439\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.465714\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.228261\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.397118\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.323504\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.171638\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.182663\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.235554\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.097012\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.175330\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.342799\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.330208\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.329721\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.248326\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.355216\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.533024\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.227113\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.273255\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.419563\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.340215\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.319343\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.283095\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.165673\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.449556\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.287944\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.332840\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.298757\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.209616\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.338910\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.262817\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.169907\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.247122\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.208217\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.684235\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.640390\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.453843\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.571898\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.262285\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.275279\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.254432\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.489530\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.588275\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.365070\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.180527\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.431656\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.364534\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.306711\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.201438\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.411528\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.202725\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.217582\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.333022\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.284057\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.277699\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.127395\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.154271\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.231703\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.174751\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.369199\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.444941\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.182807\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.462489\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.285760\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.206624\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.319039\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.402780\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.232139\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.335207\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.313161\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.360711\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.387879\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.520945\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.394548\n",
      "\n",
      "Test set: Avg. loss: 0.1206, Accuracy: 9620/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.359235\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.267668\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.325213\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.240846\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.380474\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.445274\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.452727\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.283391\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.343084\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.400199\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.417081\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.360599\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.250519\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.313634\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.257604\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.384567\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.223265\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.222601\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.335703\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.221537\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.466634\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.192168\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.224910\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.231076\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.357551\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.230155\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.518041\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.106641\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.269905\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.345770\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.289268\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.210091\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.135948\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.124362\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.400957\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.229627\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.124874\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.320025\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.390468\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.473471\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.266441\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.276278\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.323444\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.270911\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.205881\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.265123\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.339899\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.229624\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.424192\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.240878\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.247026\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.281412\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.208427\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.182561\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.306845\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.457512\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.379858\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.338514\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.376828\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.216347\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.246606\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.195748\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.141829\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.247884\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.395952\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.288972\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.388200\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.341581\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.326387\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.251904\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.389790\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.347292\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.409137\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.288733\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.250062\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.255936\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.199224\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.177671\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.225699\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.218143\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.256434\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.245684\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.260746\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.302479\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.246280\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.218756\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.315433\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.343500\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.135936\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.315863\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.259424\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.313049\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.303522\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.284638\n",
      "\n",
      "Test set: Avg. loss: 0.1121, Accuracy: 9657/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.195253\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.297947\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.152344\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.216590\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.342427\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.156585\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.317392\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.110315\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.234341\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.117373\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.247642\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.176531\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.073779\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.420310\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.275006\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.250174\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.416325\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.379957\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.252405\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.209935\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.211962\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.184384\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.220136\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.258232\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.295577\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.415681\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.215482\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.184406\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.143232\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.170892\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.203912\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.371902\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.287570\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.388400\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.202307\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.262529\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.347452\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.177505\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.171666\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.318646\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.124591\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.175419\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.352317\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.275521\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.243444\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.159963\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.328744\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.245624\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.251783\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.187580\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.264865\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.154445\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.191242\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.168160\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.396436\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.262443\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.225099\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.242948\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.340872\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.498387\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.207082\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.209347\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.276028\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.257236\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.258796\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.132040\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.260762\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.436197\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.105364\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.260508\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.103415\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.378409\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.172077\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.381458\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.449171\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.594421\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.330711\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.246669\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.236268\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.294338\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.370068\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.128182\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.247170\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.204903\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.327358\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.201294\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.378154\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.211619\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.514955\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.175139\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.247252\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.170701\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.152605\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.130219\n",
      "\n",
      "Test set: Avg. loss: 0.1031, Accuracy: 9685/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.128865\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.367014\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.264812\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.349649\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.274629\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.143834\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.343784\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.321064\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.186944\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.163386\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.395659\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.245706\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.519879\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.239588\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.231793\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.354014\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.477427\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.213089\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.248873\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.262191\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.130910\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.132779\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.232283\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.230161\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.133825\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.161326\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.368243\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.111262\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.200685\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.143029\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.263909\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.335552\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.265347\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.322240\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.428347\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.300194\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.193943\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.339946\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.190773\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.231597\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.154282\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.320404\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.181597\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.197570\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.303426\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.146647\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.303381\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.168725\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.361329\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.216465\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.278486\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.404512\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.248436\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.270565\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.172589\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.365507\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.164247\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.411775\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.125508\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.161888\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.096769\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.285345\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.405144\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.186359\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.206820\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.232236\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.204321\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.239106\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.163321\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.113829\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.426284\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.300520\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.425607\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.183140\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.194001\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.179119\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.276746\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.198608\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.319425\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.356487\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.356897\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.383551\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.274733\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.397458\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.223580\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.305151\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.229632\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.238794\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.245135\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.191607\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.241412\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.124856\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.221672\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.160065\n",
      "\n",
      "Test set: Avg. loss: 0.0973, Accuracy: 9693/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
